{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73c7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import random \n",
    "import pickle\n",
    "\n",
    "BASE_DIR = pathlib.Path().resolve().parent #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API\n",
    "SMS_SPAM_DIR = pathlib.Path().resolve()    #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/SMS-SPAM\n",
    "DATASETS_DIR = BASE_DIR / 'Datasets' #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets\n",
    "\n",
    "ZIPS_DIR = DATASETS_DIR / 'Zips'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets/Zips\n",
    "ZIPS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "#Spam-Classifier folder: START\n",
    "SPAM_CLASSIFIER_DIR = DATASETS_DIR / 'Spam-Classifier'\n",
    "\n",
    "SMS_SPAM_DIR = SPAM_CLASSIFIER_DIR / 'Sms-Spam'\n",
    "SMS_SPAM_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "YOUTUBE_SPAM_DIR = SPAM_CLASSIFIER_DIR / 'Youtube-Spam'\n",
    "YOUTUBE_SPAM_DIR.mkdir(exist_ok = True, parents = True)\n",
    "#Spam-Classifier folder : END\n",
    "\n",
    "#Exports folder: START\n",
    "EXPORT_DIR = DATASETS_DIR / 'Exports'\n",
    "EXPORT_DIR.mkdir(exist_ok = True, parents = True)\n",
    "SPAM_DATASETS_DIR = EXPORT_DIR / 'Spam_Dataset.csv'\n",
    "METADATA_EXPORT_PATH = EXPORT_DIR / 'Spam-Metadata.pkl'\n",
    "TOKENIZER_EXPORT_PATH = EXPORT_DIR / 'Spam-Tokenizer.json'\n",
    "#Exports folder: END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee6dd168",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "#Opening META_EXPORT_PATH datafile called Spam-Metadata.pkl\n",
    "#USing pickle to load dataset and storing data in dictonary called data.\n",
    "with open (METADATA_EXPORT_PATH, 'rb') as f:\n",
    "    data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3db65ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_test  = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test  = data['y_test']\n",
    "max_words = data['max_words']\n",
    "max_seq_len = data['max_seq_len']\n",
    "label_legend = data['label_legend']\n",
    "label_legend_inverted = data['label_legend_inverted']\n",
    "tokenizer = data['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51811319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69e78efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = {}\n",
    "\n",
    "#Opening TOKENIZER_EXPORT_PATH datafile called Spam-Tokenizer.json\n",
    "#USing json to load dataset and storing data in dictonary called data_json.\n",
    "with open (TOKENIZER_EXPORT_PATH, 'rb') as f:\n",
    "    data_json = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2063fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2df4052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.models import Model, Sequential \n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b4fe965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 280, 128)          35840     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 280, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 291,034\n",
      "Trainable params: 291,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embed_dim, input_length = X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3512bb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "158/158 [==============================] - 81s 499ms/step - loss: 0.2670 - accuracy: 0.8963 - val_loss: 0.1460 - val_accuracy: 0.9505\n",
      "Epoch 2/5\n",
      "158/158 [==============================] - 79s 498ms/step - loss: 0.1407 - accuracy: 0.9542 - val_loss: 0.1363 - val_accuracy: 0.9577\n",
      "Epoch 3/5\n",
      "158/158 [==============================] - 81s 515ms/step - loss: 0.1227 - accuracy: 0.9623 - val_loss: 0.1299 - val_accuracy: 0.9598\n",
      "Epoch 4/5\n",
      "158/158 [==============================] - 80s 505ms/step - loss: 0.1243 - accuracy: 0.9615 - val_loss: 0.1306 - val_accuracy: 0.9590\n",
      "Epoch 5/5\n",
      "158/158 [==============================] - 80s 510ms/step - loss: 0.1126 - accuracy: 0.9621 - val_loss: 0.1392 - val_accuracy: 0.9590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x134026580>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Starting actual training\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    " \n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size = batch_size, verbose = 1, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bfeb164",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_EXPORT_PATH = EXPORT_DIR / 'Spam_Model.h5'\n",
    "model.save(str(MODEL_EXPORT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f472e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Predicting data: \n",
    "\n",
    "def predict(text_str, max_words = 280, max_sequences = 280, tokenizer = None):\n",
    "    if not tokenizer:\n",
    "        return None\n",
    "    sequences   = tokenizer.texts_to_sequences([text_str]) #Converting input text to sequences from tokenizer \n",
    "    x_input     = pad_sequences(sequences, maxlen = max_sequences) #Padding the x-input for formatting\n",
    "    y_output    = model.predict(x_input) #passing in x-input in correct format and sequence to model.predict()\n",
    "    \n",
    "    #top_y_input = np.argmax(y_output) #Collecting index of largest value example: ([0.9837, 0.0167]), yields index 0\n",
    "    preds = y_output[0]\n",
    "   \n",
    "    labeled_preds = [{f'{label_legend_inverted[str(i)]}': x} for i, x in enumerate(preds)]\n",
    "    return labeled_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cb1bfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ham': 0.05917783}, {'spam': 0.94082224}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Get a huge discount on TV by calling this number 93718738, and visit this webpage https://stackoverflow.com/questions/19537520/attributeerror-nonetype-object-has-no-attribute-lower-python', max_words = max_words, max_sequences = max_seq_len, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8da28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f3c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98299fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637cc05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
