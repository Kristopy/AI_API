{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b73c7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import random \n",
    "import pickle\n",
    "\n",
    "BASE_DIR = pathlib.Path().resolve().parent #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API\n",
    "SMS_SPAM_DIR = pathlib.Path().resolve()    #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/SMS-SPAM\n",
    "DATASETS_DIR = BASE_DIR / 'Datasets' #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets\n",
    "\n",
    "ZIPS_DIR = DATASETS_DIR / 'Zips'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets/Zips\n",
    "ZIPS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "#Spam-Classifier folder: START\n",
    "SPAM_CLASSIFIER_DIR = DATASETS_DIR / 'Spam-Classifier'\n",
    "\n",
    "SMS_SPAM_DIR = SPAM_CLASSIFIER_DIR / 'Sms-Spam'\n",
    "SMS_SPAM_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "YOUTUBE_SPAM_DIR = SPAM_CLASSIFIER_DIR / 'Youtube-Spam'\n",
    "YOUTUBE_SPAM_DIR.mkdir(exist_ok = True, parents = True)\n",
    "#Spam-Classifier folder : END\n",
    "\n",
    "#Exports folder: START\n",
    "EXPORT_DIR = DATASETS_DIR / 'Exports'\n",
    "EXPORT_DIR.mkdir(exist_ok = True, parents = True)\n",
    "SPAM_DATASETS_DIR = EXPORT_DIR / 'Spam_Dataset.csv'\n",
    "METADATA_EXPORT_PATH = EXPORT_DIR / 'Spam-Metadata.pkl'\n",
    "TOKENIZER_EXPORT_PATH = EXPORT_DIR / 'Spam-Tokenizer.json'\n",
    "#Exports folder: END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee6dd168",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "#Opening META_EXPORT_PATH datafile called Spam-Metadata.pkl\n",
    "#USing pickle to load dataset and storing data in dictonary called data.\n",
    "with open (METADATA_EXPORT_PATH, 'rb') as f:\n",
    "    data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3db65ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_test  = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test  = data['y_test']\n",
    "max_words = data['max_words']\n",
    "max_seq_len = data['max_seq_len']\n",
    "label_legend = data['label_legend']\n",
    "label_legend_inverted = data['label_legend_inverted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51811319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69e78efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = {}\n",
    "\n",
    "#Opening TOKENIZER_EXPORT_PATH datafile called Spam-Tokenizer.json\n",
    "#USing json to load dataset and storing data in dictonary called data_json.\n",
    "with open (TOKENIZER_EXPORT_PATH, 'rb') as f:\n",
    "    data_json = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4052d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4fe965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
