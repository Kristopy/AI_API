{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c866f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import random \n",
    "import pickle\n",
    "\n",
    "BASE_DIR = pathlib.Path().resolve().parent #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API\n",
    "SMS_SPAM_DIR = pathlib.Path().resolve()    #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/SMS-SPAM\n",
    "DATASETS_DIR = BASE_DIR / 'Datasets' #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets\n",
    "\n",
    "ZIPS_DIR = DATASETS_DIR / 'Zips'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets/Zips\n",
    "ZIPS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "#Spam-Classifier folder: START\n",
    "SPAM_CLASSIFIER_DIR = DATASETS_DIR / 'Spam-Classifier'\n",
    "\n",
    "SMS_SPAM_DIR = SPAM_CLASSIFIER_DIR / 'Sms-Spam'\n",
    "SMS_SPAM_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "YOUTUBE_SPAM_DIR = SPAM_CLASSIFIER_DIR / 'Youtube-Spam'\n",
    "YOUTUBE_SPAM_DIR.mkdir(exist_ok = True, parents = True)\n",
    "#Spam-Classifier folder : END\n",
    "\n",
    "#Exports folder: START\n",
    "EXPORT_DIR = DATASETS_DIR / 'Exports'\n",
    "EXPORT_DIR.mkdir(exist_ok = True, parents = True)\n",
    "SPAM_DATASETS_DIR = EXPORT_DIR / 'Spam_Dataset.csv'\n",
    "METADATA_EXPORT_PATH = EXPORT_DIR / 'Spam-Metadata.pkl'\n",
    "TOKENIZER_EXPORT_PATH = EXPORT_DIR / 'Spam-Tokenizer.json'\n",
    "#Exports folder: END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a9dbb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_train': array([[  0,   0,   0, ...,  77, 263, 218],\n",
       "        [  0,   0,   0, ..., 261,  12,  18],\n",
       "        [  0,   0,   0, ...,  12,  46, 245],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   1],\n",
       "        [  0,   0,   0, ...,  30, 182,   9],\n",
       "        [  0,   0,   0, ..., 102,  48,  19]], dtype=int32),\n",
       " 'X_test': array([[  0,   0,   0, ...,  14,  44,  19],\n",
       "        [  0,   0,   0, ...,   7, 165,  25],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0, 122,  50],\n",
       "        [  0,   0,   0, ..., 223,  40,  59],\n",
       "        [  0,   0,   0, ...,  26, 104, 106]], dtype=int32),\n",
       " 'y_train': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'y_test': array([[0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'max_words': 280,\n",
       " 'max_seq_len': 280,\n",
       " 'label_legend': {'ham': 0, 'spam': 1},\n",
       " 'label_legend_inverted': {'0': 'ham', '1': 'spam'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "#Opening META_EXPORT_PATH datafile called Spam-Metadata.pkl\n",
    "#USing pickle to load dataset and storing data in dictonary called data.\n",
    "with open (METADATA_EXPORT_PATH, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65aff505",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_test  = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test  = data['y_test']\n",
    "max_words = data['max_words']\n",
    "max_seq_len = data['max_seq_len']\n",
    "label_legend = data['label_legend']\n",
    "label_legend_inverted = data['label_legend_inverted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1268437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a09ad5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets/Exports/Spam-Tokenizer.json')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json = {}\n",
    "\n",
    "#Opening TOKENIZER_EXPORT_PATH datafile called Spam-Tokenizer.json\n",
    "#USing pickle to load dataset and storing data in dictonary called data.\n",
    "with open (TOKENIZER_EXPORT_PATH, 'rb') as f:\n",
    "    data_json = json.load(f)\n",
    "data_json\n",
    "TOKENIZER_EXPORT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36452113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a0867e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
