{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3d327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "826f7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_DIR = pathlib.Path().resolve().parent #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API'\n",
    "NUM_REC_DIR = pathlib.Path().resolve()     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/NUM_REC'\n",
    "\n",
    "DATASETS_DIR = BASE_DIR / 'Datasets'\n",
    "\n",
    "DATASETS_NUM_REC = DATASETS_DIR / 'Datasets_NUM_REC'\n",
    "DATASETS_NUM_REC.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "\n",
    "\n",
    "ZIPS_DIR = DATASETS_NUM_REC / 'Zips'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets_Num_Rec/Zips\n",
    "ZIPS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "NUM_REC_TRAIN_IMAGE_ZIP_PATH = ZIPS_DIR  / 'num-rec-train-image-dataset.gz'\n",
    "NUM_REC_TRAIN_LABELS_ZIP_PATH = ZIPS_DIR / 'num-rec-train-labels-dataset.gz'\n",
    "\n",
    "NUM_REC_TEST_IMAGEE_ZIP_PATH = ZIPS_DIR  / 'num-rec-test-image-dataset.gz'\n",
    "NUM_REC_TEST_LABELS_ZIP_PATH = ZIPS_DIR  / 'num-rec-test-labels-dataset.gz'\n",
    "\n",
    "\n",
    "\n",
    "EXPORT_DIR = DATASETS_NUM_REC / 'Exports'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets_Num_Rec/Zips\n",
    "EXPORT_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "NUM_CLASSIFIER_DIR = DATASETS_NUM_REC / 'NUM_REC_Classifier'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets_Num_Rec/Zips\n",
    "NUM_CLASSIFIER_DIR.mkdir(exist_ok = True, parents = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877f6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#URL of dataset for number recognition from images. \n",
    "NUM_REC_TRAIN_IMAGE_ZIP = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
    "NUM_REC_TRAIN_LABEL_ZIP = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
    "\n",
    "NUM_REC_TEST_IMAGE_ZIP = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
    "NUM_REC_TEST_LABEL_ZIP = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28511821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9680k  100 9680k    0     0  17.7M      0 --:--:-- --:--:-- --:--:-- 17.7M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 28881  100 28881    0     0   454k      0 --:--:-- --:--:-- --:--:--  454k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1610k  100 1610k    0     0  9700k      0 --:--:-- --:--:-- --:--:-- 9700k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4542  100  4542    0     0  75700      0 --:--:-- --:--:-- --:--:-- 75700\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!curl $NUM_REC_TRAIN_IMAGE_ZIP -o $NUM_REC_TRAIN_IMAGE_ZIP_PATH\n",
    "!curl $NUM_REC_TRAIN_LABEL_ZIP -o $NUM_REC_TRAIN_LABELS_ZIP_PATH\n",
    "\n",
    "!curl $NUM_REC_TEST_IMAGE_ZIP -o $NUM_REC_TEST_IMAGEE_ZIP_PATH\n",
    "!curl $NUM_REC_TEST_LABEL_ZIP -o $NUM_REC_TEST_LABELS_ZIP_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c4027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets/Datasets_NUM_REC/Zips/num-rec-train-image-dataset.gz\n",
      "/Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets/Datasets_NUM_REC/NUM_REC_Classifier/Train_datasets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRAIN_DATASETS_DIR = NUM_CLASSIFIER_DIR / 'Train_datasets'\n",
    "TRAIN_DATASETS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "TEST_DATASETS_DIR = NUM_CLASSIFIER_DIR / 'Test_datasets'\n",
    "TEST_DATASETS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "print(NUM_REC_TRAIN_IMAGE_ZIP_PATH)\n",
    "print(TRAIN_DATASETS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245bbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -f $NUM_REC_TRAIN_IMAGE_ZIP_PATH\n",
    "!gunzip -f $NUM_REC_TRAIN_LABELS_ZIP_PATH\n",
    "!gunzip -f $NUM_REC_TEST_IMAGEE_ZIP_PATH \n",
    "!gunzip -f $NUM_REC_TEST_LABELS_ZIP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f60355c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in ZIPS_DIR.resolve().iterdir():\n",
    "    if not file.stem.startswith('.'):\n",
    "        if 'train' in file.stem:\n",
    "            Transfer_train = TRAIN_DATASETS_DIR/file.stem\n",
    "            !cp $file $Transfer_train\n",
    "        else:\n",
    "            Transfer_test = TEST_DATASETS_DIR/file.stem\n",
    "            !cp $file $Transfer_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ccddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num-rec-test-image-dataset\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASETS_DIR\n",
    "TEST_DATASETS_DIR\n",
    "\n",
    "files_data = []\n",
    "for path in TRAIN_DATASETS_DIR.parent.glob('*'): \n",
    "    for files in path.glob('*'):\n",
    "        files_data.append(files)\n",
    "print(files_data[0].stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55b72f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "846120c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "imdb  = tf.keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b8f1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_data separated as usually by train and test - approx 0.33 devided. X_data are images formed by matrices with\n",
    "#values ranging from 0-255 grey-scale --> need to normalize for convinience \n",
    "\n",
    "#y_data are int values of images at same indeces. \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9fc5782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "random_idx = random.randint(0,len(X_train))\n",
    "\n",
    "#Good overview over X_data and y_data \n",
    "plt.imshow(X_train[random_idx], cmap=plt.cm.binary) #Everything works fine. A matrix of number from 0-9\n",
    "print(y_train[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fff3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing input values to range from 0-1 --> by dividing by max value of 255. \n",
    "X_train =X_train/255\n",
    "X_test =X_test/255\n",
    "#Be carefull --> If this cell is re-run without re-running upper cells, it will divide the current X_data on 255 again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e28bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "949b5ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 22:16:52.278901: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2320 - accuracy: 0.9318\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0970 - accuracy: 0.9701\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0672 - accuracy: 0.9791\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0523 - accuracy: 0.9834\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0396 - accuracy: 0.9871\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0333 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x166390250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67361c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 837us/step - loss: 0.0759 - accuracy: 0.9783\n",
      "0.07594134658575058 0.9782999753952026\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b84c1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model saved and stored to correct path.\n",
    "MODEL_EXPORT_PATH = EXPORT_DIR / 'Num_Rec_Model.h5'\n",
    "model.save(str(MODEL_EXPORT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "805b5626",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: 5\n",
      "Correct Output:  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x166cc2b50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test model by running predictions: \n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "random_idx = random.randint(0,len(X_test))\n",
    "\n",
    "cp_model = load_model(MODEL_EXPORT_PATH)\n",
    "predictions = cp_model.predict([X_test])\n",
    "\n",
    "\n",
    "print('Predictions:', np.argmax(predictions[random_idx]))\n",
    "print('Correct Output: ', y_test[random_idx])\n",
    "plt.imshow(X_test[random_idx], cmap=plt.cm.binary) #Everything works fine. A matrix of number from 0-9\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
