{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3d327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "826f7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_DIR = pathlib.Path().resolve().parent #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API'\n",
    "NUM_REC_DIR = pathlib.Path().resolve()     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/NUM_REC'\n",
    "\n",
    "DATASETS_DIR = BASE_DIR / 'Datasets'\n",
    "\n",
    "DATASETS_NUM_REC = DATASETS_DIR / 'Datasets_NUM_REC'\n",
    "DATASETS_NUM_REC.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "\n",
    "\n",
    "ZIPS_DIR = DATASETS_NUM_REC / 'Zips'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets_Num_Rec/Zips\n",
    "ZIPS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "NUM_REC_TRAIN_IMAGE_ZIP_PATH = ZIPS_DIR  / 'num-rec-train-image-dataset.gz'\n",
    "NUM_REC_TRAIN_LABELS_ZIP_PATH = ZIPS_DIR / 'num-rec-train-labels-dataset.gz'\n",
    "\n",
    "NUM_REC_TEST_IMAGEE_ZIP_PATH = ZIPS_DIR  / 'num-rec-test-image-dataset.gz'\n",
    "NUM_REC_TEST_LABELS_ZIP_PATH = ZIPS_DIR  / 'num-rec-test-labels-dataset.gz'\n",
    "\n",
    "\n",
    "\n",
    "EXPORT_DIR = DATASETS_NUM_REC / 'Exports'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets_Num_Rec/Zips\n",
    "EXPORT_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "NUM_CLASSIFIER_DIR = DATASETS_NUM_REC / 'NUM_REC_Classifier'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets_Num_Rec/Zips\n",
    "NUM_CLASSIFIER_DIR.mkdir(exist_ok = True, parents = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877f6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#URL of dataset for number recognition from images. \n",
    "NUM_REC_TRAIN_IMAGE_ZIP = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
    "NUM_REC_TRAIN_LABEL_ZIP = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
    "\n",
    "NUM_REC_TEST_IMAGE_ZIP = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
    "NUM_REC_TEST_LABEL_ZIP = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28511821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9680k  100 9680k    0     0  17.7M      0 --:--:-- --:--:-- --:--:-- 17.7M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 28881  100 28881    0     0   454k      0 --:--:-- --:--:-- --:--:--  454k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1610k  100 1610k    0     0  9700k      0 --:--:-- --:--:-- --:--:-- 9700k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4542  100  4542    0     0  75700      0 --:--:-- --:--:-- --:--:-- 75700\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!curl $NUM_REC_TRAIN_IMAGE_ZIP -o $NUM_REC_TRAIN_IMAGE_ZIP_PATH\n",
    "!curl $NUM_REC_TRAIN_LABEL_ZIP -o $NUM_REC_TRAIN_LABELS_ZIP_PATH\n",
    "\n",
    "!curl $NUM_REC_TEST_IMAGE_ZIP -o $NUM_REC_TEST_IMAGEE_ZIP_PATH\n",
    "!curl $NUM_REC_TEST_LABEL_ZIP -o $NUM_REC_TEST_LABELS_ZIP_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c4027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets/Datasets_NUM_REC/Zips/num-rec-train-image-dataset.gz\n",
      "/Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets/Datasets_NUM_REC/NUM_REC_Classifier/Train_datasets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRAIN_DATASETS_DIR = NUM_CLASSIFIER_DIR / 'Train_datasets'\n",
    "TRAIN_DATASETS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "TEST_DATASETS_DIR = NUM_CLASSIFIER_DIR / 'Test_datasets'\n",
    "TEST_DATASETS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "print(NUM_REC_TRAIN_IMAGE_ZIP_PATH)\n",
    "print(TRAIN_DATASETS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245bbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -f $NUM_REC_TRAIN_IMAGE_ZIP_PATH\n",
    "!gunzip -f $NUM_REC_TRAIN_LABELS_ZIP_PATH\n",
    "!gunzip -f $NUM_REC_TEST_IMAGEE_ZIP_PATH \n",
    "!gunzip -f $NUM_REC_TEST_LABELS_ZIP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f60355c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in ZIPS_DIR.resolve().iterdir():\n",
    "    if not file.stem.startswith('.'):\n",
    "        if 'train' in file.stem:\n",
    "            Transfer_train = TRAIN_DATASETS_DIR/file.stem\n",
    "            !cp $file $Transfer_train\n",
    "        else:\n",
    "            Transfer_test = TEST_DATASETS_DIR/file.stem\n",
    "            !cp $file $Transfer_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ccddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num-rec-test-image-dataset\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASETS_DIR\n",
    "TEST_DATASETS_DIR\n",
    "\n",
    "files_data = []\n",
    "for path in TRAIN_DATASETS_DIR.parent.glob('*'): \n",
    "    for files in path.glob('*'):\n",
    "        files_data.append(files)\n",
    "print(files_data[0].stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55b72f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "846120c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "imdb  = tf.keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b8f1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_data separated as usually by train and test - approx 0.33 devided. X_data are images formed by matrices with\n",
    "#values ranging from 0-255 grey-scale --> need to normalize for convinience \n",
    "\n",
    "#y_data are int values of images at same indeces. \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9fc5782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "random_idx = random.randint(0,len(X_train))\n",
    "\n",
    "#Good overview over X_data and y_data \n",
    "plt.imshow(X_train[random_idx], cmap=plt.cm.binary) #Everything works fine. A matrix of number from 0-9\n",
    "print(y_train[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fff3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing input values to range from 0-1 --> by dividing by max value of 255. \n",
    "X_train =X_train/255\n",
    "X_test =X_test/255\n",
    "#Be carefull --> If this cell is re-run without re-running upper cells, it will divide the current X_data on 255 again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e28bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "949b5ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 22:16:52.278901: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2320 - accuracy: 0.9318\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0970 - accuracy: 0.9701\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0672 - accuracy: 0.9791\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0523 - accuracy: 0.9834\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0396 - accuracy: 0.9871\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0333 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x166390250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67361c20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mj/wcl2fbds1kgb_7_f8c49l9l80000gn/T/ipykernel_46322/2467907357.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b84c1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model saved and stored to correct path.\n",
    "MODEL_EXPORT_PATH = EXPORT_DIR / 'Num_Rec_Model.h5'\n",
    "model.save(str(MODEL_EXPORT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "805b5626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: 4\n",
      "Correct Output:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1688a7640>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test model by running predictions: \n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "random_idx = random.randint(0,len(X_test))\n",
    "\n",
    "cp_model = load_model(MODEL_EXPORT_PATH)\n",
    "predictions = cp_model.predict([X_test])\n",
    "\n",
    "\n",
    "print('Predictions:', np.argmax(predictions[random_idx]))\n",
    "print('Correct Output: ', y_test[random_idx])\n",
    "plt.imshow(X_test[random_idx], cmap=plt.cm.binary) #Everything works fine. A matrix of number from 0-9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e49573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
