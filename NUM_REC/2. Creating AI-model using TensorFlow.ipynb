{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3d327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826f7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_DIR = pathlib.Path().resolve().parent #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API'\n",
    "NUM_REC_DIR = pathlib.Path().resolve()     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/NUM_REC'\n",
    "\n",
    "DATASETS_DIR = BASE_DIR / 'Datasets'\n",
    "\n",
    "DATASETS_NUM_REC = DATASETS_DIR / 'Datasets_NUM_REC'\n",
    "DATASETS_NUM_REC.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "\n",
    "\n",
    "ZIPS_DIR = DATASETS_NUM_REC / 'Zips'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets_Num_Rec/Zips\n",
    "ZIPS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "NUM_REC_TRAIN_IMAGE_ZIP_PATH = ZIPS_DIR  / 'num-rec-train-image-dataset.gz'\n",
    "NUM_REC_TRAIN_LABELS_ZIP_PATH = ZIPS_DIR / 'num-rec-train-labels-dataset.gz'\n",
    "\n",
    "NUM_REC_TEST_IMAGEE_ZIP_PATH = ZIPS_DIR  / 'num-rec-test-image-dataset.gz'\n",
    "NUM_REC_TEST_LABELS_ZIP_PATH = ZIPS_DIR  / 'num-rec-test-labels-dataset.gz'\n",
    "\n",
    "\n",
    "\n",
    "EXPORT_DIR = DATASETS_NUM_REC / 'Exports'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets_Num_Rec/Zips\n",
    "EXPORT_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "NUM_CLASSIFIER_DIR = DATASETS_NUM_REC / 'NUM_REC_Classifier'     #Check: /Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets_Num_Rec/Zips\n",
    "NUM_CLASSIFIER_DIR.mkdir(exist_ok = True, parents = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877f6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#URL of dataset for number recognition from images. \n",
    "NUM_REC_TRAIN_IMAGE_ZIP = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
    "NUM_REC_TRAIN_LABEL_ZIP = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
    "\n",
    "NUM_REC_TEST_IMAGE_ZIP = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
    "NUM_REC_TEST_LABEL_ZIP = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28511821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9680k  100 9680k    0     0  3815k      0  0:00:02  0:00:02 --:--:-- 3814k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 28881  100 28881    0     0   397k      0 --:--:-- --:--:-- --:--:--  397k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1610k  100 1610k    0     0  5111k      0 --:--:-- --:--:-- --:--:-- 5111k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4542  100  4542    0     0  72095      0 --:--:-- --:--:-- --:--:-- 72095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!curl $NUM_REC_TRAIN_IMAGE_ZIP -o $NUM_REC_TRAIN_IMAGE_ZIP_PATH\n",
    "!curl $NUM_REC_TRAIN_LABEL_ZIP -o $NUM_REC_TRAIN_LABELS_ZIP_PATH\n",
    "\n",
    "!curl $NUM_REC_TEST_IMAGE_ZIP -o $NUM_REC_TEST_IMAGEE_ZIP_PATH\n",
    "!curl $NUM_REC_TEST_LABEL_ZIP -o $NUM_REC_TEST_LABELS_ZIP_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c4027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets/Datasets_NUM_REC/Zips/num-rec-train-image-dataset.gz\n",
      "/Users/kristoffervarslott/Documents/Python.py/AI_API/Datasets/Datasets_NUM_REC/NUM_REC_Classifier/Train_datasets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRAIN_DATASETS_DIR = NUM_CLASSIFIER_DIR / 'Train_datasets'\n",
    "TRAIN_DATASETS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "TEST_DATASETS_DIR = NUM_CLASSIFIER_DIR / 'Test_datasets'\n",
    "TEST_DATASETS_DIR.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "print(NUM_REC_TRAIN_IMAGE_ZIP_PATH)\n",
    "print(TRAIN_DATASETS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "245bbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -f $NUM_REC_TRAIN_IMAGE_ZIP_PATH\n",
    "!gunzip -f $NUM_REC_TRAIN_LABELS_ZIP_PATH\n",
    "!gunzip -f $NUM_REC_TEST_IMAGEE_ZIP_PATH \n",
    "!gunzip -f $NUM_REC_TEST_LABELS_ZIP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60355c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in ZIPS_DIR.resolve().iterdir():\n",
    "    if not file.stem.startswith('.'):\n",
    "        if 'train' in file.stem:\n",
    "            Transfer_train = TRAIN_DATASETS_DIR/file.stem\n",
    "            !cp $file $Transfer_train\n",
    "        else:\n",
    "            Transfer_test = TEST_DATASETS_DIR/file.stem\n",
    "            !cp $file $Transfer_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ccddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num-rec-test-image-dataset\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASETS_DIR\n",
    "TEST_DATASETS_DIR\n",
    "\n",
    "files_data = []\n",
    "for path in TRAIN_DATASETS_DIR.parent.glob('*'): \n",
    "    for files in path.glob('*'):\n",
    "        files_data.append(files)\n",
    "print(files_data[0].stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b72f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "846120c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "imdb  = tf.keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b8f1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_data separated as usually by train and test - approx 0.33 devided. X_data are images formed by matrices with\n",
    "#values ranging from 0-255 grey-scale --> need to normalize for convinience \n",
    "\n",
    "#y_data are int values of images at same indeces. \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9fc5782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOt0lEQVR4nO3df6hVdbrH8c9zaxIrI8uTmUrODCciLlx/bCRLUxn6odGPgYjxj8krxokynIERjClLCqLCZoq8DKiJdpmrjcxUknFvJoMxIdFWumnJLW+YZUc92h+j/+S1ee4fZxUnO+u7Tnut/cOe9wsOZ5/1Oeusp00f1z577bO/5u4C8MP3T+0eAEBrUHYgCMoOBEHZgSAoOxDE2a082KhRo3zChAmtPCQQyv79+3X06FEbLCtVdjO7SdKzks6StMbdn0h9/4QJE1Sv18scEkBCrVbLzRp+GG9mZ0n6N0lzJF0laZ6ZXdXozwPQXGV+Z58qaZ+7f+zuJyVtlHRbNWMBqFqZso+V9OmArz/Ltn2LmfWYWd3M6n19fSUOB6CMpj8b7+6r3L3m7rWurq5mHw5AjjJlPyhp/ICvx2XbAHSgMmV/R1K3mf3YzM6R9AtJm6sZC0DVGr705u6nzOx+Sf+l/ktva939/comA1CpUtfZ3f01Sa9VNAuAJuLlskAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4E0dIlm9F59u7dm8xXr16dzDdu3JjMDx06lJudf/75yX1ffvnlZH7ttdcm82HDhuVmp06dSu7b29ubzIuMGTMmmZ99duurx5kdCIKyA0FQdiAIyg4EQdmBICg7EARlB4LgOvsPwLFjx3KzDRs2JPddvHhxMjezhmYayv4nTpxI7rto0aJkfuuttybze++9Nzdbt25dct/HHnssmRdZtmxZMl++fHmpn9+IUmU3s/2Sjkv6StIpd69VMRSA6lVxZp/t7kcr+DkAmojf2YEgypbdJb1uZjvNrGewbzCzHjOrm1m9r6+v5OEANKps2ae7+2RJcyQtMrPrTv8Gd1/l7jV3r3V1dZU8HIBGlSq7ux/MPh+R9JKkqVUMBaB6DZfdzM4zsxFf35Z0g6Q9VQ0GoFplno0fLeml7Drq2ZL+w93/s5Kp8L08/fTTudmTTz5Z6mdPmzYtmS9ZsiSZX3rppQ0fu7u7O5kX/c350qVLc7NNmzYl9y37+oJ9+/aV2r8ZGi67u38s6V8qnAVAE3HpDQiCsgNBUHYgCMoOBEHZgSD4E9czwOeff57MX3311YZ/9oEDB5L5xRdfnMyHDx/e8LHL2rFjRzLfunVriyb5roceeqhtx87DmR0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHguA6+xng5MmTyfzo0fz3+5w5c2Zy33HjxjU0Uyc4fvx4Mn/hhRdys82bNyf3XbNmTTJfsGBBMr/yyiuTeTtwZgeCoOxAEJQdCIKyA0FQdiAIyg4EQdmBILjOfgbYtWtXMj98+HBuNmvWrIqn6Rw33HBDMt+yZUtuVnQd/YILLkjmRa9f6ESc2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCK6znwFefPHFZD5+/Pjc7Lnnnqt6nJY5duxYMn/88ceT+TPPPJObnXvuucl9Fy9enMzvuuuuZN6JCs/sZrbWzI6Y2Z4B2y4ys61m9lH2eWRzxwRQ1lAexq+TdNNp2x6QtM3duyVty74G0MEKy+7ub0r64rTNt0lan91eL+n2ascCULVGn6Ab7e692e1DkkbnfaOZ9ZhZ3czqfX19DR4OQFmln413d5fkiXyVu9fcvdbV1VX2cAAa1GjZD5vZGEnKPh+pbiQAzdBo2TdLmp/dni/plWrGAdAshdfZzWyDpFmSRpnZZ5IekfSEpD+Z2UJJn0i6s5lD/tAVvf/5hx9+mMyvvvrq3KxoffV22r59ezJftmxZMn/rrbeS+ZQpU3KzW265pdSxz0SFZXf3eTnRzyqeBUAT8XJZIAjKDgRB2YEgKDsQBGUHguBPXDvAiBEjknnq0pokrVu3Lje75557kvuuWLEimRfNVuTRRx/NzR555JHkvmZW6tgzZszIzX6Il9aKcGYHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSC4zn4GKLomvHv37tysaGni2bNnJ/Obb745mRfN9vzzz+dmRdfRi5abvu+++5J5d3d3Mo+GMzsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBMF19jPAZZddlsyvu+663GzHjh3JfRcsWJDMr7jiimS+Z8+eZJ4yffr0ZL5p06Zk3slvk92JOLMDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBBcZ/8BmDRpUsP7fvnll8m8zHV0Serp6cnNnnrqqeS+Zd+zHt9WeGY3s7VmdsTM9gzYttzMDprZu9nH3OaOCaCsoTyMXyfppkG2/97dJ2Yfr1U7FoCqFZbd3d+U9EULZgHQRGWeoLvfzN7LHuaPzPsmM+sxs7qZ1fv6+kocDkAZjZb9D5J+KmmipF5JT+d9o7uvcveau9e6uroaPByAshoqu7sfdvev3P0fklZLmlrtWACq1lDZzWzMgC9/Lqnc9RkATVd4nd3MNkiaJWmUmX0m6RFJs8xsoiSXtF9SehFwJH366afJvOj90bds2dLwsd294X0laeXKlcm8aHa0TmHZ3X3eIJvz3/kfQEfi5bJAEJQdCIKyA0FQdiAIyg4EwZ+4DtHx48dzs6I/A925c2cyX7x4cTIvWto4lRe9DfXBgwdLHRtnDs7sQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAE19kza9euTebPPvtsblb27ZaLTJs2LZkvWbIkNyt6m+k77rgjmR84cCCZX3/99ckcnYMzOxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4EwXX2zNtvv53Mm3kt/eGHH07mS5cuTebDhw9v+NiTJ09O5kX/3du3b0/m3d3d33smNAdndiAIyg4EQdmBICg7EARlB4Kg7EAQlB0Iguvsmblz5ybz1atXN/yzp0yZkswXLlyYzMsuq5wyY8aMZF70371ixYpknvp7+QsvvDC5L6pVeGY3s/Fm9lcz+8DM3jezX2XbLzKzrWb2UfZ5ZPPHBdCooTyMPyXpN+5+laSrJS0ys6skPSBpm7t3S9qWfQ2gQxWW3d173X1Xdvu4pL2Sxkq6TdL67NvWS7q9STMCqMD3eoLOzCZImiTpbUmj3b03iw5JGp2zT4+Z1c2s3tfXV2ZWACUMuexmdr6kP0v6tbv/fWDm/c8gDfoskruvcveau9e6urpKDQugcUMqu5n9SP1F/6O7/yXbfNjMxmT5GElHmjMigCoUXnqz/jV7n5e0191/NyDaLGm+pCeyz680ZcIWOeecc5L5qFGjcrNjx44l9921a1cyv/zyy5P5Nddck8xnz56dm40ePehvV99YuXJlMi9asvnGG29M5sOGDUvmaJ2hXGe/VtIvJe02s3ezbb9Vf8n/ZGYLJX0i6c6mTAigEoVld/e/Scr75/1n1Y4DoFl4uSwQBGUHgqDsQBCUHQiCsgNB8CeumTlz5iTzTZs25WYPPvhgct8dO3Y0NNNQ9y/z84v+fHbs2LHJfN68ecm8zNtco1qc2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCK6zD9HMmTNzs9dffz257xtvvJHMt2zZkszXrFmTzMsoWi767rvvTuaXXHJJleOgiTizA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQ1szlgE9Xq9W8Xq+37HhANLVaTfV6fdB3g+bMDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBFJbdzMab2V/N7AMze9/MfpVtX25mB83s3exjbvPHBdCoobx5xSlJv3H3XWY2QtJOM9uaZb939xXNGw9AVYayPnuvpN7s9nEz2yspvUwIgI7zvX5nN7MJkiZJejvbdL+ZvWdma81sZM4+PWZWN7N6X19fuWkBNGzIZTez8yX9WdKv3f3vkv4g6aeSJqr/zP/0YPu5+yp3r7l7raurq/zEABoypLKb2Y/UX/Q/uvtfJMndD7v7V+7+D0mrJU1t3pgAyhrKs/Em6XlJe939dwO2jxnwbT+XtKf68QBUZSjPxl8r6ZeSdpvZu9m230qaZ2YTJbmk/ZLuacJ8ACoylGfj/yZpsL+Pfa36cQA0C6+gA4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBNHSJZvNrE/SJwM2jZJ0tGUDfD+dOlunziUxW6OqnO1ydx/0/d9aWvbvHNys7u61tg2Q0KmzdepcErM1qlWz8TAeCIKyA0G0u+yr2nz8lE6drVPnkpitUS2Zra2/swNonXaf2QG0CGUHgmhL2c3sJjP7HzPbZ2YPtGOGPGa238x2Z8tQ19s8y1ozO2JmewZsu8jMtprZR9nnQdfYa9NsHbGMd2KZ8bbed+1e/rzlv7Ob2VmSPpR0vaTPJL0jaZ67f9DSQXKY2X5JNXdv+wswzOw6SSckveDu/5xte0rSF+7+RPYP5Uh3X9ohsy2XdKLdy3hnqxWNGbjMuKTbJf2r2njfJea6Uy2439pxZp8qaZ+7f+zuJyVtlHRbG+boeO7+pqQvTtt8m6T12e316v+fpeVyZusI7t7r7ruy28clfb3MeFvvu8RcLdGOso+V9OmArz9TZ6337pJeN7OdZtbT7mEGMdrde7PbhySNbucwgyhcxruVTltmvGPuu0aWPy+LJ+i+a7q7T5Y0R9Ki7OFqR/L+38E66drpkJbxbpVBlhn/Rjvvu0aXPy+rHWU/KGn8gK/HZds6grsfzD4fkfSSOm8p6sNfr6CbfT7S5nm+0UnLeA+2zLg64L5r5/Ln7Sj7O5K6zezHZnaOpF9I2tyGOb7DzM7LnjiRmZ0n6QZ13lLUmyXNz27Pl/RKG2f5lk5ZxjtvmXG1+b5r+/Ln7t7yD0lz1f+M/P9KerAdM+TM9RNJ/519vN/u2SRtUP/Duv9T/3MbCyVdLGmbpI8kvSHpog6a7d8l7Zb0nvqLNaZNs01X/0P09yS9m33Mbfd9l5irJfcbL5cFguAJOiAIyg4EQdmBICg7EARlB4Kg7EAQlB0I4v8B8CxeGeb9mhUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "random_idx = random.randint(0,len(X_train))\n",
    "\n",
    "#Good overview over X_data and y_data \n",
    "plt.imshow(X_train[random_idx], cmap=plt.cm.binary) #Everything works fine. A matrix of number from 0-9\n",
    "print(y_train[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fff3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing input values to range from 0-1 --> by dividing by max value of 255. \n",
    "X_train =X_train/255\n",
    "X_test =X_test/255\n",
    "#Be carefull --> If this cell is re-run without re-running upper cells, it will divide the current X_data on 255 again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e28bf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-02 13:58:05.134151: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "949b5ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-02 13:58:05.588229: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1875/1875 [==============================] - 2s 960us/step - loss: 0.2243 - accuracy: 0.9350\n",
      "Epoch 2/6\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0935 - accuracy: 0.9711\n",
      "Epoch 3/6\n",
      "1875/1875 [==============================] - 2s 956us/step - loss: 0.0646 - accuracy: 0.9796\n",
      "Epoch 4/6\n",
      "1875/1875 [==============================] - 2s 962us/step - loss: 0.0511 - accuracy: 0.9832\n",
      "Epoch 5/6\n",
      "1875/1875 [==============================] - 2s 961us/step - loss: 0.0396 - accuracy: 0.9868\n",
      "Epoch 6/6\n",
      "1875/1875 [==============================] - 2s 957us/step - loss: 0.0316 - accuracy: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x170eb48b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67361c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 642us/step - loss: 0.0866 - accuracy: 0.9756\n",
      "0.0866045132279396 0.975600004196167\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b84c1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model saved and stored to correct path.\n",
    "MODEL_EXPORT_PATH = EXPORT_DIR / 'Num_Rec_Model.h5'\n",
    "model.save(str(MODEL_EXPORT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "805b5626",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: 0\n",
      "Correct Output:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x171715070>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test model by running predictions: \n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "random_idx = random.randint(0,len(X_test))\n",
    "\n",
    "cp_model = load_model(MODEL_EXPORT_PATH)\n",
    "predictions = cp_model.predict([X_test])\n",
    "\n",
    "\n",
    "print('Predictions:', np.argmax(predictions[random_idx]))\n",
    "print('Correct Output: ', y_test[random_idx])\n",
    "plt.imshow(X_test[random_idx], cmap=plt.cm.binary) #Everything works fine. A matrix of number from 0-9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5efa732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "METADATA = {\n",
    "    'X_test': X_test.tolist(),\n",
    "    'y_test': y_test.tolist(),\n",
    "    'val_acc': val_acc,\n",
    "    'val_loss': val_loss \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99a6363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_EXPORT_PATH = EXPORT_DIR / 'Num_Rec_Metadata.json'\n",
    "\n",
    "with open (METADATA_EXPORT_PATH, \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(METADATA, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825cef25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
